{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4 - 1) // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_index_soda:940\n",
      "split_index:3200\n",
      "(4000, 12, 24, 72)\n",
      "(4000, 12, 24, 72)\n",
      "(4000, 24, 1)\n",
      "(4000, 24, 1)\n",
      "(384, 12, 24, 72)\n",
      "384\n",
      "(1176, 12, 24, 72)\n",
      "(1176, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import random #shuffle\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "def CMIPdata(Xdata, Ydata, out , myform):\n",
    "    inp1 = Dataset(Xdata,'r')\n",
    "    inp2 = Dataset(Ydata,'r')\n",
    "    sst_1 = np.zeros((myform,140,12,24,72))\n",
    "\n",
    "    #首年序列\n",
    "    #i= 21个模式\n",
    "    for i in range(myform):\n",
    "        sst_1[i,:,:,:,:] = inp1.variables['sst1'][1+141*i:141+141*i,0:12,:,:]\n",
    "    #(21,140,12,24,72)\n",
    "    #首年序列\n",
    "\n",
    "    \n",
    "    #flatted扁平化                                             \n",
    "    sst_2 = np.zeros((myform,1680,24,72))\n",
    "    for i in range(myform):\n",
    "        for j in range(140):\n",
    "            sst_2[i,j*12:(j+1)*12,:,:] = sst_1[i,j,:,:,:]\n",
    "    \n",
    "        #(21,1680,24,72)\n",
    "        #每个模式 139*12+1 = 1680 个序列 序列长度为12\n",
    "\n",
    "    #丢弃1个月 1862.1\n",
    "    sst_2 = sst_2[:,1:,:,:]\n",
    "    #(form,1679,24,72)\n",
    "\n",
    "\n",
    "    winsize = 12\n",
    "    #winnum = 1679-winsize +1 #1668\n",
    "    \"\"\"跳跃六个月滑窗 = 6\"\"\"\n",
    "    ts=6 \n",
    "    #(1679-12)/6+1 =27\n",
    "    winnum=int((1679-12)/ts +1) \n",
    "    \n",
    "    sst_3 = np.zeros((myform,winnum,12,24,72))\n",
    "    for i in range(myform):\n",
    "        for j in range(winnum):\n",
    "            #print(j)\n",
    "            sst_3[i,j,:,:,:] = sst_2[i,(j*ts):(j*ts)+winsize,:,:]\n",
    "            \n",
    "\n",
    "    sst_4 = np.zeros((int(winnum*myform),12,24,72))\n",
    "    #t300_4 = np.zeros((int(winnum*myform),12,24,72))\n",
    "    for i in range(myform):\n",
    "        sst_4[i*winnum:(i+1)*winnum,:,:,:] = sst_3[i,:,:,:,:]\n",
    "\n",
    "\n",
    "    #sst_4 = sst_4.swapaxes(1, 3)\n",
    "    trX = sst_4\n",
    "    del sst_1,sst_2,sst_3,sst_4\n",
    "    #trX = trX.reshape(int(winnum*myform),12,1728)\n",
    "\n",
    "    #保存np数组\n",
    "    #(5859, 12, 24, 72, 2)\n",
    "    #np.save(\"./CMIPdata/CMIP_trX_21_ts6_out.npy\",trX) \n",
    "\n",
    "    #label\n",
    "    #平铺\n",
    "    pr_1 = np.zeros(((myform),1692))#21,1692\n",
    "    for i in range(myform):\n",
    "        for j in range(141):\n",
    "            pr_1[i,j*12:(j+1)*12] = inp2.variables['pr'][(141*i)+j,:,0,0]\n",
    "            \n",
    "    #out\n",
    "    pr_2 =  np.zeros((myform,winnum,out))#form,1668,1\n",
    "    for i in range(myform):\n",
    "        for j in range(winnum):\n",
    "            pr_2[i,j,:] = pr_1[i,(j*ts):(j*ts)+out]\n",
    "\n",
    "    trY = np.zeros((int(winnum*myform),out))#form*1668,1\n",
    "    for i in range(myform):\n",
    "        trY[i*winnum:(i+1)*winnum,:] = pr_2[i,:,:]\n",
    "\n",
    "    #np.save(\"./CMIPdata/CMIP_trY_21_ts6_out%s.npy\"%out,trY)\n",
    "    trY_decoder_input = np.zeros((int(winnum*myform),out))\n",
    "    trY_decoder_input[:,1:] = trY[:,:-1]\n",
    "\n",
    "    #return trX[1:,:,:] ,trY.reshape(-1,24,1)[1:,:,:] ,trY_decoder_input\n",
    "    return trX ,trY.reshape(-1,24,1) ,trY_decoder_input.reshape(-1,24,1)\n",
    "\n",
    "def SODAdata(Xdata, Ydata, out):\n",
    "    inp1 = Dataset(Xdata,'r')\n",
    "    inp2 = Dataset(Ydata,'r')\n",
    "\n",
    "\n",
    "    #time_step = 1 month                                               \n",
    "    sst_1 = np.zeros((99,12,24,72))\n",
    "    #t300_1 = np.zeros((99,12,24,72))\n",
    "\n",
    "    sst_1[:,:,:,:] = inp1.variables['sst'][1:,0:12,:,:]\n",
    "    #sst_1[:,:,:,:] = inp1.variables['t300'][1:,0:12,:,:]\n",
    "    #(99,12,24,72)\n",
    "    #1872-1970\n",
    "\n",
    "    sst_2 = np.zeros((1188,24,72))\n",
    "    #t300_2 = np.zeros((1188,24,72))\n",
    "\n",
    "    for i in range(99):\n",
    "        sst_2[i*12:(i+1)*12,:,:] = sst_1[i,:,:,:]\n",
    "        #t300_2[i*12:(i+1)*12,:,:] = t300_1[i,:,:,:]\n",
    "    #(1188,24,72)\n",
    "    #丢弃一个月，便于制作滑窗序列\n",
    "    sst_2 = sst_2[1:,:,:]\n",
    "    #t300_2 = t300_2[1:,:,:]#(1187,24,72)\n",
    "\n",
    "    sst_3 = np.zeros((1176,12,24,72))\n",
    "    #t300_3 = np.zeros((1176,12,24,72))\n",
    "    #滑窗\n",
    "    for i in range(1176):\n",
    "        sst_3[i:,:,:] = sst_2[i:i+12,:,:]\n",
    "        #t300_3[i,:,:,:] = sst_2[i:i+12,:,:]\n",
    "    #(1176,12,24,72)\n",
    "    trX = sst_3\n",
    "\n",
    "    #channel = 2\n",
    "    #trX = np.zeros((1176,12,24,72,2))\n",
    "    #trX[:,:,:,:,0] = sst_3\n",
    "    #trX[:,:,:,:,1] = t300_3\n",
    "\n",
    "    #保存np数组\n",
    "    #np.save(\"./SODAdata/SODA_trX_ts1_out.npy\",trX)\n",
    "\n",
    "    #label\n",
    "    inpv2 = np.zeros((1200))\n",
    "    for i in range(100):\n",
    "        inpv2[i*12:(i+1)*12] = inp2.variables['pr'][i,:,0,0]\n",
    "    #(1200)\n",
    "\n",
    "    #out = 1\n",
    "    trY = np.zeros((1176,out,1))\n",
    "    #滑窗\n",
    "    for i in range(1176):\n",
    "        trY[i,:,0] = inpv2[i:i+out]#24\n",
    "    #(1176,24)\n",
    "\n",
    "    #np.save(\"./SODAdata/SODA_trY_ts1_out%s.npy\"%out,trY) \n",
    "    return trX ,trY\n",
    "\n",
    "def GOSDAdata(Xdata, Ydata, out):\n",
    "    #test data\n",
    "    inp11 = Dataset(Xdata,'r')\n",
    "    inp22 = Dataset(Ydata,'r')\n",
    "                                              \n",
    "    sst_11 = np.zeros((33,12,24,72)) #1983-2015\n",
    "    #t300_11 = np.zeros((33,12,24,72))\n",
    "\n",
    "    sst_11[:,:,:,:] = inp11.variables['sst'][3:,0:12,:,:]\n",
    "    #t300_11[:,:,:,:] = inp11.variables['t300'][3:,0:12,:,:]\n",
    "    #(33,12,24,72)\n",
    "\n",
    "    sst_22 = np.zeros((396,24,72))\n",
    "    #t300_22 = np.zeros((396,24,72))\n",
    "\n",
    "    for i in range(33):\n",
    "        sst_22[i*12:(i+1)*12,:,:] = sst_11[i,:,:,:]\n",
    "        #t300_22[i*12:(i+1)*12,:,:] = t300_11[i,:,:,:]\n",
    "    #(396,24,72)\n",
    "    #丢弃一个月，便于制作滑窗序列\n",
    "    sst_22 = sst_22[1:,:,:]\n",
    "    #t300_22 = t300_22[1:,:,:]#(395,24,72)\n",
    "\n",
    "    #滑窗\n",
    "    winsize = 12\n",
    "    winnum = 395-winsize + 1 #384\n",
    "    sst_33 = np.zeros((winnum, winsize, 24, 72))#(384, 12, 24, 72)\n",
    "    #t300_33 = np.zeros((winnum, winsize, 24, 72))\n",
    "\n",
    "    for i in range(winnum):\n",
    "        sst_33[i,:,:,:] = sst_22[i:i+12,:,:]\n",
    "        #t300_33[i,:,:,:] = t300_22[i:i+12,:,:]\n",
    "    #(384,12,24,72)\n",
    "\n",
    "\n",
    "    #channel = 2\n",
    "    #testX = np.zeros((winnum,12,24,72,2))#384\n",
    "    #testX[:,:,:,:,0] = sst_33\n",
    "    #testX[:,:,:,:,1] = t300_33\n",
    "    #sst_33 = sst_33.swapaxes(1, 3)\n",
    "\n",
    "    testX = sst_33#384\n",
    "    #testX[:,:,:,1] = t300_33.reshape(384,12,1728)\n",
    "    del sst_11,sst_22,sst_33\n",
    "    #del t300_11,t300_22,t300_33\n",
    "    #testX = testX.reshape(384,12,3456)\n",
    "\n",
    "    #label\n",
    "    inpv22 = np.zeros((408))#2017-1984 +1=34\n",
    "    for i in range(34):\n",
    "        inpv22[i*12:(i+1)*12] = inp22.variables['pr'][i+2,:,0,0]# +2:从1984开始\n",
    "        #(408)\n",
    "\n",
    "    testY = np.zeros((winnum,out,1))\n",
    "    #out = 1\n",
    "    #滑窗\n",
    "    for i in range(winnum):\n",
    "        testY[i,:,0] = inpv22[i:i+out]#24\n",
    "    #(384,out,1)\n",
    "\n",
    "    return testX, testY\n",
    "\n",
    "trX, trY, trY_decoder_input = CMIPdata('/home/d/Q/liyanqiu/saconvlstm/CMIP5.input.36mon.1861_2001.nc',\\\n",
    "                                          '/home/d/Q/liyanqiu/saconvlstm/CMIP5.label.12mon.1863_2003.nc', 24,  21)\n",
    "\n",
    "testX, testY = GOSDAdata('/home/d/Q/liyanqiu/saconvlstm/GODAS.input.36mon.1980_2015.nc',\\\n",
    "                         '/home/d/Q/liyanqiu/saconvlstm/GODAS.label.12mon.1982_2017.nc', 24)\n",
    "\n",
    "trX_SODA, trY_SODA = SODAdata('/home/d/Q/liyanqiu/saconvlstm/SODA.input.36mon.1871_1970.nc',\n",
    "                              '/home/d/Q/liyanqiu/saconvlstm/SODA.label.12mon.1873_1972.nc',24)\n",
    "\n",
    "indices = np.arange(trX.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "trX = trX[indices]\n",
    "trY = trY[indices]\n",
    "trY_decoder_input = trY_decoder_input[indices]\n",
    "\n",
    "indices_soda = np.arange(trX_SODA.shape[0])\n",
    "np.random.shuffle(indices_soda)\n",
    "trX_SODA = trX_SODA[indices_soda]\n",
    "trY_SODA = trY_SODA[indices_soda]\n",
    "\n",
    "\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    \"\"\"自定义DataLoader\"\"\"\n",
    "\n",
    "    def __init__(self, enc_inputs, dec_inputs, dec_outputs):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.enc_inputs = enc_inputs\n",
    "        self.dec_inputs = dec_inputs\n",
    "        self.dec_outputs = dec_outputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.enc_inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.enc_inputs[idx], self.dec_inputs[idx], self.dec_outputs[idx]\n",
    "    \n",
    "batch_size = 32\n",
    "trainsize = 4000\n",
    "trX = trX[:trainsize]\n",
    "trY = trY[:trainsize]\n",
    "trY_decoder_input = trY_decoder_input[:trainsize]\n",
    "\n",
    "split_index = int(trX.shape[0]*0.8)\n",
    "split_index_soda = int(trX_SODA.shape[0]*0.8)\n",
    "print(\"split_index_soda:\" + str(split_index_soda))\n",
    "\n",
    "print(\"split_index:\" + str(split_index))\n",
    "loader_train = Data.DataLoader(\n",
    "    MyDataSet(\n",
    "        trX[:split_index].astype(np.float32), \n",
    "        trY_decoder_input[:split_index].astype(np.float32), \n",
    "        trY[:split_index].astype(np.float32)), \n",
    "    batch_size, shuffle = True)\n",
    "\n",
    "loader_valid = Data.DataLoader(\n",
    "    MyDataSet(\n",
    "        trX[split_index:].astype(np.float32), \n",
    "        trY_decoder_input[split_index:].astype(np.float32), \n",
    "        trY[split_index:].astype(np.float32)), \n",
    "    batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "loader_train_sado = Data.DataLoader(\n",
    "    MyDataSet(\n",
    "        trX_SODA[:split_index_soda].astype(np.float32), \n",
    "        trX_SODA[:split_index_soda].astype(np.float32), \n",
    "        trY_SODA[:split_index_soda].astype(np.float32)), \n",
    "    batch_size, shuffle = True)\n",
    "\n",
    "loader_valid_soda = Data.DataLoader(\n",
    "    MyDataSet(\n",
    "        trX_SODA[split_index_soda:].astype(np.float32), \n",
    "        trX_SODA[split_index_soda:].astype(np.float32), \n",
    "        trY_SODA[split_index_soda:].astype(np.float32)), \n",
    "    batch_size, shuffle=False)\n",
    "\n",
    "print(trX.shape)\n",
    "print(trX.shape)\n",
    "print(trY_decoder_input.shape)\n",
    "print(trY.shape)\n",
    "print(testX.shape)\n",
    "print(len(testX))\n",
    "print(trX_SODA.shape)\n",
    "print(trY_SODA.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if on cuda: True\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "src_len = 12\n",
    "tgt_len = 24\n",
    "tgt_vocab_size = 1 # out unit\n",
    "\n",
    "d_model = 512  #  加入CNN后提取出来的维度\n",
    "#d_model = 24*72\n",
    "d_ff = 2048  # FeedForward dimension (两次线性层中的隐藏层 512->2048->512，线性层是用来做特征提取的），当然最后会再接一个projection层\n",
    "d_k = d_v = 64  # dimension of K(=Q), V（Q和K的维度需要相同，这里为了方便让K=V）\n",
    "encoder_n_layers = 1  # number of Encoder  Layer（Block的个数）\n",
    "decoder_n_layers = 1  # number of  Decoder Layer（Block的个数）\n",
    "n_heads = 8 # number of heads in Multi-Head Attention（有几套头）\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):# padding mask\n",
    "    # pad mask的作用：在对value向量加权平均的时候，可以让pad对应的alpha_ij=0，这样注意力就不会考虑到pad向量\n",
    "    \"\"\"这里的q,k表示的是两个序列（跟注意力机制的q,k没有关系），例如encoder_inputs (x1,x2,..xm)和encoder_inputs (x1,x2..xm)\n",
    "    encoder和decoder都可能调用这个函数，所以seq_len视情况而定\n",
    "    seq_q: [batch_size, seq_len]\n",
    "    seq_k: [batch_size, seq_len]\n",
    "    \"\"\"\n",
    "    batch_size, len_q, = seq_q.size(0), seq_q.size(1)  # 这个seq_q只是用来expand维度的\n",
    "    batch_size, len_k, = seq_k.size(0), seq_k.size(1)\n",
    "    # eq(zero) is PAD token\n",
    "    a = torch.ones(batch_size, 1 ,len_k)\n",
    "    pad_attn_mask = a.data.eq(0)\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k).to(device)  # [batch_size, len_q, len_k] 构成一个立方体(batch_size个这样的矩阵)\n",
    "\n",
    "def get_attn_subsequence_mask(seq): # subsequence mask\n",
    "    \"\"\"\n",
    "    seq: [batch_size, tgt_len]\n",
    "    \"\"\"\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    # attn_shape: [batch_size, tgt_len, tgt_len]\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)  # 生成一个上三角矩阵\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()\n",
    "    # print(subsequence_mask.data)\n",
    "    return subsequence_mask.to(device)  # [batch_size, tgt_len, tgt_len]\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        Q: [batch_size, n_heads, len_q, d_k]\n",
    "        K: [batch_size, n_heads, len_k, d_k]\n",
    "        V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n",
    "        说明：在encoder-decoder的Attention层中len_q(q1,..qt)和len_k(k1,...km)可能不同\n",
    "        \"\"\"\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k)  # scores : [batch_size, n_heads, len_q, len_k]\n",
    "        # mask矩阵填充scores（用-1e9填充scores中与attn_mask中值为1位置相对应的元素）\n",
    "        scores.masked_fill_(attn_mask, -1e9)  # Fills elements of self tensor with value where mask is True.\n",
    "\n",
    "        attn = nn.Softmax(dim=-1)(scores)  # 对最后一个维度(v)做softmax\n",
    "        # scores : [batch_size, n_heads, len_q, len_k] * V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        context = torch.matmul(attn, V)  # context: [batch_size, n_heads, len_q, d_v]\n",
    "        # context：[[z1,z2,...],[...]]向量, attn注意力稀疏矩阵（用于可视化的）\n",
    "        return context, attn\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"这个Attention类可以实现:\n",
    "    Encoder的Self-Attention\n",
    "    Decoder的Masked Self-Attention\n",
    "    Encoder-Decoder的Attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=False)  # q,k必须维度相同，不然无法做点积\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n",
    "        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n",
    "\n",
    "    def forward(self, input_Q, input_K, input_V, attn_mask):\n",
    "        \"\"\"\n",
    "        input_Q: [batch_size, len_q, d_model]\n",
    "        input_K: [batch_size, len_k, d_model]\n",
    "        input_V: [batch_size, len_v(=len_k), d_model]\n",
    "        attn_mask: [batch_size, seq_len, seq_len]\n",
    "        \"\"\"\n",
    "        residual, batch_size = input_Q, input_Q.size(0)\n",
    "        # 下面的多头的参数矩阵是放在一起做线性变换的，然后再拆成多个头，这是工程实现的技巧\n",
    "        # B: batch_size, S:seq_len, D: dim\n",
    "        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, Head, W) -trans-> (B, Head, S, W)\n",
    "        #           线性变换               拆成多头\n",
    "\n",
    "        # Q: [batch_size, n_heads, len_q, d_k]\n",
    "        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        # K: [batch_size, n_heads, len_k, d_k] # K和V的长度一定相同，维度可以不同\n",
    "        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1, 2)\n",
    "        # V: [batch_size, n_heads, len_v(=len_k), d_v]\n",
    "        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1, 2)\n",
    "\n",
    "        # 因为是多头，所以mask矩阵要扩充成4维的\n",
    "        # attn_mask: [batch_size, seq_len, seq_len] -> [batch_size, n_heads, seq_len, seq_len]\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
    "\n",
    "        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n",
    "        context, attn = ScaledDotProductAttention()(Q, K, V, attn_mask)\n",
    "        # 下面将不同头的输出向量拼接在一起\n",
    "        # context: [batch_size, n_heads, len_q, d_v] -> [batch_size, len_q, n_heads * d_v]\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v)\n",
    "        # 再做一个projection\n",
    "        output = self.fc(context)  # [batch_size, len_q, d_model]\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual), attn\n",
    "    \n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_ff, d_model, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        inputs: [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return nn.LayerNorm(d_model).to(device)(output + residual)  # [batch_size, seq_len, d_model]\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
    "        \"\"\"E\n",
    "        enc_inputs: [batch_size, src_len, d_model]\n",
    "        enc_self_attn_mask: [batch_size, src_len, src_len]  mask矩阵(pad mask or sequence mask)\n",
    "        \"\"\"\n",
    "        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n",
    "        # 第一个enc_inputs * W_Q = Q\n",
    "        # 第二个enc_inputs * W_K = K\n",
    "        # 第三个enc_inputs * W_V = V\n",
    "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs,\n",
    "                                               enc_self_attn_mask)  # enc_inputs to same Q,K,V（未线性变换前）\n",
    "        enc_outputs = self.pos_ffn(enc_outputs)\n",
    "        # enc_outputs: [batch_size, src_len, d_model]\n",
    "        return enc_outputs, attn\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention()\n",
    "        self.dec_enc_attn = MultiHeadAttention()\n",
    "        self.pos_ffn = PoswiseFeedForwardNet()\n",
    "\n",
    "    def forward(self, dec_inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, tgt_len, d_model]\n",
    "        enc_outputs: [batch_size, src_len, d_model]\n",
    "        dec_self_attn_mask: [batch_size, tgt_len, tgt_len]\n",
    "        dec_enc_attn_mask: [batch_size, tgt_len, src_len]\n",
    "        \"\"\"\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len]\n",
    "        #dec_outputs, dec_self_attn = self.dec_self_attn(dec_inputs, dec_inputs, dec_inputs, dec_self_attn_mask)  # 这里的Q,K,V全是Decoder自己的输入\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "        #dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_outputs, enc_outputs, enc_outputs,dec_enc_attn_mask)  # Attention层的Q(来自decoder) 和 K,V(来自encoder)\n",
    "        dec_outputs, dec_enc_attn = self.dec_enc_attn(dec_inputs, enc_outputs, enc_outputs,dec_enc_attn_mask)\n",
    "        dec_outputs = self.pos_ffn(dec_outputs)  # [batch_size, tgt_len, d_model]\n",
    "        #return dec_outputs, dec_self_attn, dec_enc_attn  # dec_self_attn, dec_enc_attn这两个是为了可视化的\n",
    "        return dec_outputs, dec_enc_attn\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        #self.src_emb = nn.Embedding(src_vocab_size, d_model)  # token Embedding\n",
    "        self.conv1=nn.Conv2d(1,30,(4,8))\n",
    "        #self.Tanh=nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)# stride 默认值是kernel_size\n",
    "        self.conv2=nn.Conv2d(30,30,(4,8))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv3=nn.Conv2d(30,30,(2,4))\n",
    "        self.fc = nn.Linear(540, d_model)# 改动 540 = CNN卷积得到的大小\n",
    "        \n",
    "        self.pos_emb = PositionalEncoding(d_model)  # Transformer中位置编码时固定的，不需要学习\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(encoder_n_layers)])\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        \"\"\"\n",
    "        enc_inputs: [batch_size, src_len,24,72]\n",
    "        \"\"\"\n",
    "        #enc_outputs = self.src_emb(enc_inputs)  # [batch_size, src_len, d_model]\n",
    "        \n",
    "        enc_outputs = enc_inputs.reshape(-1, 24, 72).unsqueeze(1)\n",
    "        #print(enc_outputs.size())\n",
    "        enc_outputs = self.conv1(enc_outputs)\n",
    "        #enc_outputs = self.Tanh(enc_outputs)\n",
    "        #print(enc_outputs.size())\n",
    "        enc_outputs = self.pool1(enc_outputs)\n",
    "        enc_outputs = self.conv2(enc_outputs)\n",
    "        #enc_outputs = self.Tanh(enc_outputs)\n",
    "        #print(enc_outputs.size())\n",
    "        enc_outputs = self.pool2(enc_outputs)\n",
    "        enc_outputs = self.conv3(enc_outputs)\n",
    "        #enc_outputs = self.Tanh(enc_outputs)\n",
    "        #print(enc_outputs.size())\n",
    "        # torch.Size([32, 12, 540])\n",
    "        enc_outputs = enc_outputs.reshape(-1, src_len, enc_outputs.size(-1) * enc_outputs.size(-2) * enc_outputs.size(-3))\n",
    "        enc_outputs = self.fc(enc_outputs)\n",
    "        #[-1, src_len,30 * 18 * 6]\n",
    "        #print(enc_outputs.size())\n",
    "        \n",
    "        #enc_outputs = enc_inputs.reshape(-1, 12,24*72)\n",
    "\n",
    "        enc_outputs = self.pos_emb(enc_outputs.transpose(0, 1)).transpose(0, 1)  # [batch_size, src_len, d_model]\n",
    "        # Encoder输入序列的pad mask矩阵\n",
    "        enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs)  # [batch_size, src_len, src_len]\n",
    "        enc_self_attns = []  # 画热力图等\n",
    "        for layer in self.layers:  # for循环访问nn.ModuleList对象\n",
    "            # 上一个block的输出enc_outputs作为当前block的输入\n",
    "            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n",
    "            enc_outputs, enc_self_attn = layer(enc_outputs,\n",
    "                                               enc_self_attn_mask)  # 传入的enc_outputs其实是input，传入mask矩阵是因为你要做self attention\n",
    "            enc_self_attns.append(enc_self_attn)  # 这个只是为了可视化\n",
    "        return enc_outputs, enc_self_attns\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        #self.tgt_emb = nn.Embedding(tgt_vocab_size, d_model)  # Decoder输入的embed词表 注意浮点数不可以进行词嵌入\n",
    "        #self.expand_linear = nn.Linear(tgt_vocab_size, d_model, bias=False)#改动部分，作用不大\n",
    "        self.pos_emb = PositionalEncoding(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer() for _ in range(decoder_n_layers)])  # Decoder的blocks\n",
    "\n",
    "    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "        \"\"\"\n",
    "        dec_inputs: [batch_size, tgt_len]\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        enc_outputs: [batch_size, src_len, d_model]   # 用在Encoder-Decoder Attention层\n",
    "        \"\"\"\n",
    "        \n",
    "        #dec_outputs = self.expand_linear(dec_inputs).to(device) # [batch_size, 24, d_model]\n",
    "        # 修改未完成 tgt的扩维 到d_model\n",
    "        #dec_outputs = dec_inputs.repeat(1,1,d_model) \n",
    "        dec_outputs = self.pos_emb(dec_inputs.transpose(0, 1)).transpose(0, 1).to(device)  \n",
    "        # [batch_size, tgt_len, d_model]\n",
    "        # Decoder输入序列的pad mask矩阵（这个例子中decoder是没有加pad的，实际应用中都是有pad填充的）\n",
    "        dec_self_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs).to(device)  # [batch_size, tgt_len, tgt_len]\n",
    "        # Masked Self_Attention：当前时刻是看不到未来的信息的\n",
    "        dec_self_attn_subsequence_mask = get_attn_subsequence_mask(dec_inputs).to(\n",
    "            device)  # [batch_size, tgt_len, tgt_len]\n",
    "\n",
    "        # Decoder中把两种mask矩阵相加（既屏蔽了pad的信息，也屏蔽了未来时刻的信息）\n",
    "        dec_self_attn_mask = torch.gt((dec_self_attn_pad_mask + dec_self_attn_subsequence_mask),\n",
    "                                      0).to(device)  # [batch_size, tgt_len, tgt_len]; torch.gt比较两个矩阵的元素，大于则返回1，否则返回0\n",
    "\n",
    "        # 这个mask主要用于encoder-decoder attention层\n",
    "        # get_attn_pad_mask主要是enc_inputs的pad mask矩阵(因为enc是处理K,V的，求Attention时是用v1,v2,..vm去加权的，要把pad对应的v_i的相关系数设为0，这样注意力就不会关注pad向量)\n",
    "        #                       dec_inputs只是提供expand的size的\n",
    "        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs)  # [batc_size, tgt_len, src_len]\n",
    "\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attn: [batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [batch_size, h_heads, tgt_len, src_len]\n",
    "            # Decoder的Block是上一个Block的输出dec_outputs（变化）和Encoder网络的输出enc_outputs（固定）\n",
    "            #dec_outputs, dec_self_attn, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            dec_outputs, dec_enc_attn = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
    "            #dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model]\n",
    "        return dec_outputs, dec_self_attns, dec_enc_attns\n",
    "\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False).to(device)\n",
    "        #self.object_query = nn.Parameter(torch.rand(batch_size, tgt_len, 1))#均匀分布\n",
    "        self.object_query = nn.Parameter(torch.rand(1,tgt_len, d_model))#均匀分布\n",
    "\n",
    "    def forward(self, enc_inputs):\n",
    "        \"\"\"Transformers的输入：两个序列\n",
    "        enc_inputs: [batch_size, src_len]\n",
    "        修改\n",
    "        enc_inputs: [batch_size, src_len, 24,72]\n",
    "        dec_inputs: [batch_size, tgt_len,1]\n",
    "        \"\"\"\n",
    "        # tensor to store decoder outputs\n",
    "        # outputs = torch.zeros(batch_size, tgt_len, tgt_vocab_size).to(self.device)\n",
    "\n",
    "        # enc_outputs: [batch_size, src_len, d_model], enc_self_attns: [n_layers, batch_size, n_heads, src_len, src_len]\n",
    "        # 经过Encoder网络后，得到的输出还是[batch_size, src_len, d_model]\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs)\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\n",
    "        #dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        dec_inputs = self.object_query.repeat(enc_inputs.size(0), 1, 1)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        # dec_outputs: [batch_size, tgt_len, d_model] -> dec_logits: [batch_size, tgt_len, tgt_vocab_size]\n",
    "        dec_logits = self.projection(dec_outputs)\n",
    "        #return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns\n",
    "        return dec_logits, enc_self_attns, dec_self_attns, dec_enc_attns\n",
    "\n",
    "\n",
    "model = Transformer().to(device)\n",
    "\n",
    "        \n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, truth):\n",
    "        \"\"\"计算相关系数\n",
    "        Args:\n",
    "            pred ([type]): [batch_size, 24, 1]\n",
    "            truth ([type]): [batch_size, 24, 1]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [batch_size个相关系数的均值]\n",
    "        \"\"\"\n",
    "        mse = 0.\n",
    "        cost = torch.pow((truth.squeeze() - pred.squeeze()), 2)\n",
    "        #print(cost.size())\n",
    "        k = torch.arange(1, 25).unsqueeze(0).to(device)\n",
    "        loss = torch.mul(cost, k)\n",
    "        #print(loss.size())\n",
    "        \n",
    "        return  torch.mean(loss)\n",
    "\n",
    "class corrcoef(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, fake_Y, Y):\n",
    "        \"\"\"计算相关系数\n",
    "        Args:\n",
    "            pred ([type]): [batch_size, 24, 1]\n",
    "            truth ([type]): [batch_size, 24, 1]\n",
    "\n",
    "        Returns:\n",
    "            [type]: [batch_size个相关系数的均值]\n",
    "        \"\"\"\n",
    "        for i in range(24):\n",
    "            fake_Y, Y = fake_Y.reshape(-1), Y.reshape(-1)\n",
    "        fake_Y_mean, Y_mean = torch.mean(fake_Y), torch.mean(Y)\n",
    "        corr = (torch.sum((fake_Y - fake_Y_mean) * (Y - Y_mean))) / (\n",
    "                    torch.sqrt(torch.sum((fake_Y - fake_Y_mean) ** 2)) * torch.sqrt(torch.sum((Y - Y_mean) ** 2)))\n",
    "        #print(cost.size())\n",
    "        return corr\n",
    "\n",
    " \n",
    "#criterion = MyLoss()\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.99)  # 用adam的话效果不好\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                lr=1e-3,\n",
    "                 betas=(0.9, 0.99),\n",
    "                 eps=1e-08,\n",
    "                 weight_decay=1e-6,\n",
    "                 amsgrad=False)\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print(\"if on cuda:\",next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training...\n",
      "================================================================================2022-02-24 14:27:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/d/Q/liyanqiu/transformer2.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=16'>17</a>\u001b[0m enc_inputs, dec_inputs, dec_outputs \u001b[39m=\u001b[39m enc_inputs\u001b[39m.\u001b[39mto(device), dec_inputs\u001b[39m.\u001b[39mto(device), dec_outputs\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=17'>18</a>\u001b[0m \u001b[39m#outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=18'>19</a>\u001b[0m outputs, enc_self_attns, dec_self_attns, dec_enc_attns \u001b[39m=\u001b[39m model(enc_inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=19'>20</a>\u001b[0m \u001b[39m# print(outputs.size()) [32, 24, 1]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m#loss = criterion(outputs.view(-1), dec_outputs.view(-1)) \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000006vscode-remote?line=21'>22</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, dec_outputs) \n",
      "File \u001b[0;32m~/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/d/Q/liyanqiu/transformer2.ipynb Cell 5'\u001b[0m in \u001b[0;36mTransformer.forward\u001b[0;34m(self, enc_inputs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=314'>315</a>\u001b[0m \u001b[39m# dec_outputs: [batch_size, tgt_len, d_model], dec_self_attns: [n_layers, batch_size, n_heads, tgt_len, tgt_len], dec_enc_attn: [n_layers, batch_size, tgt_len, src_len]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=315'>316</a>\u001b[0m \u001b[39m#dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_inputs, enc_outputs)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=316'>317</a>\u001b[0m dec_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobject_query\u001b[39m.\u001b[39mrepeat(enc_inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=317'>318</a>\u001b[0m dec_outputs, dec_self_attns, dec_enc_attns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(dec_inputs, enc_inputs, enc_outputs)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=318'>319</a>\u001b[0m \u001b[39m# dec_outputs: [batch_size, tgt_len, d_model] -> dec_logits: [batch_size, tgt_len, tgt_vocab_size]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=319'>320</a>\u001b[0m dec_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection(dec_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/d/Q/liyanqiu/transformer2.ipynb Cell 5'\u001b[0m in \u001b[0;36mDecoder.forward\u001b[0;34m(self, dec_inputs, enc_inputs, enc_outputs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=254'>255</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=255'>256</a>\u001b[0m \u001b[39mdec_inputs: [batch_size, tgt_len]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=256'>257</a>\u001b[0m \u001b[39menc_inputs: [batch_size, src_len]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=257'>258</a>\u001b[0m \u001b[39menc_outputs: [batch_size, src_len, d_model]   # 用在Encoder-Decoder Attention层\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=258'>259</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=260'>261</a>\u001b[0m \u001b[39m#dec_outputs = self.expand_linear(dec_inputs).to(device) # [batch_size, 24, d_model]\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=261'>262</a>\u001b[0m dec_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtgt_emb(dec_inputs)\u001b[39m.\u001b[39mto(device) \u001b[39m# [batch_size, 24, d_model]\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=262'>263</a>\u001b[0m \u001b[39m#dec_outputs = dec_inputs.repeat(1,1,d_model) \u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B10.6.69.64/home/d/Q/liyanqiu/transformer2.ipynb#ch0000004vscode-remote?line=263'>264</a>\u001b[0m dec_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_emb(dec_inputs\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(device)  \n",
      "File \u001b[0;32m~/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/sparse.py?line=156'>157</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/sparse.py?line=157'>158</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/sparse.py?line=158'>159</a>\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/modules/sparse.py?line=159'>160</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py:2043\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2036'>2037</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2037'>2038</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2038'>2039</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2039'>2040</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2040'>2041</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2041'>2042</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> <a href='file:///home/d/anaconda3/envs/enso-q/lib/python3.8/site-packages/torch/nn/functional.py?line=2042'>2043</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import datetime\n",
    "dfhistory = pd.DataFrame(columns = [\"epoch\",\"loss\",\"val_loss\"]) \n",
    "print(\"Start Training...\")\n",
    "nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(\"==========\"*8 + \"%s\"%nowtime)\n",
    "epoch = 20\n",
    "for epoch in range(1,epoch+1):\n",
    "    #train----------------------------------------------------\n",
    "  model.train()\n",
    "  loss_sum = 0.0\n",
    "  step = 1\n",
    "  for step,(enc_inputs, dec_inputs, dec_outputs) in enumerate(loader_train, 1):\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # 正向\n",
    "      enc_inputs, dec_inputs, dec_outputs = enc_inputs.to(device), dec_inputs.to(device), dec_outputs.to(device)\n",
    "      #outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "      outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs)\n",
    "      # print(outputs.size()) [32, 24, 1]\n",
    "      #loss = criterion(outputs.view(-1), dec_outputs.view(-1)) \n",
    "      loss = criterion(outputs, dec_outputs) \n",
    "\n",
    "      # 反向\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # print\n",
    "      loss_sum += loss.item()\n",
    "      if step%100 == 0:\n",
    "        print((\"[step = %d] loss: %.3f, \") % (step, loss_sum/step))\n",
    "\n",
    "\n",
    "  #valid\n",
    "  model.eval()\n",
    "  val_loss_sum = 0.0\n",
    "  val_step = 1\n",
    "\n",
    "  for val_step, (enc_inputs, dec_inputs, dec_outputs) in enumerate(loader_valid, 1):\n",
    "    with torch.no_grad():# 节点不进行求梯度\n",
    "      enc_inputs, dec_inputs, dec_outputs = enc_inputs.to(device), dec_inputs.to(device), dec_outputs.to(device)\n",
    "      #outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs, dec_inputs)\n",
    "      outputs, enc_self_attns, dec_self_attns, dec_enc_attns = model(enc_inputs)\n",
    "      #val_loss = criterion(outputs.view(-1), dec_outputs.view(-1)) \n",
    "      val_loss =criterion(outputs, dec_outputs) \n",
    "\n",
    "    val_loss_sum += val_loss.item()\n",
    "\n",
    "  # log\n",
    "  info = (epoch, loss_sum/step, val_loss_sum/val_step)\n",
    "  dfhistory.loc[epoch-1] = info # epoch从1开始 index -1\n",
    "\n",
    "  # print\n",
    "  print((\"\\nEPOCH = %d, loss = %.3f,\"+\" val_loss = %.3f, \")% info)\n",
    "  nowtime = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "  print(\"\\n\"+\"==========\"*8 + \"%s\"%nowtime)\n",
    "\n",
    "print('Finished Training...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test No.100\n",
      "test No.200\n",
      "test No.300\n",
      "[0.8637147  0.82816319 0.77898118 0.72236124 0.66423581 0.60621761\n",
      " 0.54341419 0.47300315 0.40469113 0.3506554  0.29673081 0.2551246\n",
      " 0.20078937 0.17830393 0.15450149 0.12861622 0.12047569 0.11346102\n",
      " 0.10877293 0.10337794 0.09910139 0.10340895 0.10403057 0.10518739]\n",
      "sum :8.307319885032488\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================================\n",
    "# 预测阶段\n",
    "# testX, testY\n",
    "\n",
    "seqout = []\n",
    "for i in range(len(testX)):\n",
    "  enc_input = torch.from_numpy(testX[i].reshape(1, 12, 24, 72).astype(np.float32)).to(device)\n",
    "  testout,_ ,_ , _ = model(enc_input)\n",
    "  #print(testout.size())\n",
    "  theout = testout.squeeze().cpu().detach().numpy()\n",
    "  seqout.append(theout)\n",
    "  if (i+1)%100 ==0:\n",
    "    print(\"test No.\" + str(i+1))\n",
    "\n",
    "\n",
    "cor = np.zeros((24))\n",
    "for i in range(24):\n",
    "  cor[i] = np.corrcoef(testY.reshape(384,24)[:,i],np.array(seqout)[:,i])[0,1]\n",
    "print(cor)\n",
    "print(\"sum :\" + str(np.sum(cor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d/anaconda3/envs/q/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test No.100\n",
      "test No.200\n",
      "test No.300\n",
      "[-0.08421008 -0.0175227   0.14862161  0.01897893 -0.05390481  0.03450693\n",
      "  0.03083762  0.03079215  0.09039667  0.06329426  0.06929582 -0.02636757\n",
      " -0.03288357  0.08332342  0.02014678  0.03223532 -0.02548352  0.06354501\n",
      " -0.01569905  0.02670549  0.09425747  0.05165895  0.0173925   0.01824862]\n",
      "sum :0.6381662530264707\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================================================\n",
    "# 预测阶段\n",
    "# testX, testY\n",
    "def test_decoder(modle, enc_input):\n",
    "  enc_input = torch.from_numpy(enc_input.astype(np.float32)).to(device)\n",
    "    \n",
    "  enc_outputs, enc_self_attns = model.encoder(enc_input)\n",
    "  dec_input = torch.zeros(1, 0, 1).type_as(enc_input.data)# type转变\n",
    "  next_symbol = 0.\n",
    "  # print(enc_outputs.size())\n",
    "  # print(enc_input.size())\n",
    "    \n",
    "  for i in range(24):\n",
    "      # next_symbol两维\n",
    "      # print(i)\n",
    "      dec_input = torch.cat([dec_input.to(device), torch.tensor([[[next_symbol]]], dtype=enc_input.dtype).to(device)], -2)\n",
    "      # print(dec_input.size())\n",
    "      # print(dec_input.data)\n",
    "      dec_outputs, _, _ = model.decoder(dec_input, enc_input, enc_outputs)\n",
    "      # print(dec_outputs.size())\n",
    "      projected = model.projection(dec_outputs)\n",
    "      # print(projected.size())\n",
    "      prob = projected.squeeze(0)\n",
    "      # print(\"prob\")\n",
    "      # print(prob.data)\n",
    "      next_word = prob.data[-1].item()\n",
    "      next_symbol = next_word\n",
    "      # print(next_word)\n",
    "        \n",
    "  dec_input = torch.cat([dec_input.to(device), torch.tensor([[[next_symbol]]], dtype=enc_input.dtype).to(device)], -2)\n",
    "  dec_predict = dec_input[:, 1:]\n",
    "  return dec_predict\n",
    "\n",
    "seqout = []\n",
    "for i in range(len(testX)):\n",
    "  testout = test_decoder(model, testX[i].reshape(1, 12, 24, 72))\n",
    "  seqout.append(testout.squeeze().cpu().numpy())\n",
    "  if (i+1)%100 ==0:\n",
    "    print(\"test No.\" + str(i+1))\n",
    "\n",
    "\n",
    "cor = np.zeros((24))\n",
    "for i in range(24):\n",
    "  cor[i] = np.corrcoef(testY.reshape(384,24)[:,i],np.array(seqout)[:,i])[0,1]\n",
    "print(cor)\n",
    "print(\"sum :\" + str(np.sum(cor)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bba8c7d9c8496bd6992670a29c4e9a9a45ed2b8a8c8d7c9266649db153117bd"
  },
  "kernelspec": {
   "display_name": "Python [conda env:enso-q]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
